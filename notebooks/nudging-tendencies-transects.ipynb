{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nudging tendencies transects\n",
    "\n",
    "Make transects of nudging and physics tendencies from a coarse nudged run and compare to the fine-res apparent sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import intake\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib import rc, pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "rc('animation', html='html5')\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(**{'xtick.labelsize': 'small', 'ytick.labelsize': 'small', 'axes.labelsize': 'small'})\n",
    "from IPython.display import HTML\n",
    "from vcm.catalog import catalog as CATALOG\n",
    "from vcm.safe import get_variables\n",
    "from vcm.calc import thermo\n",
    "from vcm.fv3.metadata import standardize_fv3_diagnostics\n",
    "from vcm import encode_time, interpolate_unstructured\n",
    "from loaders.mappers._fine_resolution_budget import FineResolutionSources\n",
    "from loaders.mappers import XarrayMapper, GeoMapper\n",
    "from typing import Mapping, Sequence, Union, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2F_URL = 'gs://vcm-ml-experiments/2021-04-13-n2f-c3072/3-hrly-ave-rad-precip-setting-30-min-rad-timestep-shifted-start-tke-edmf-3-hrly-ave-physics-tendencies'\n",
    "FINE_RES_ZARR = 'gs://vcm-ml-experiments/default/2021-04-27/2020-05-27-40-day-X-SHiELD-simulation/fine-res-budget.zarr'\n",
    "VERIFICATION_ENTRY = '40day_c48_atmos_8xdaily_may2020'\n",
    "VAR_MAPPING = {'air_temperature': '1', 'specific_humidity': '2'}\n",
    "PLOT_VARS=[\n",
    "    'pressure',\n",
    "    '{var:s}_tendency_due_to_nudging',\n",
    "    'tendency_of_{var}_due_to_fv3_physics',\n",
    "    '{var}',\n",
    "    'PRATEsfc',\n",
    "    'column_integrated_nQ{num}',\n",
    "    'total_precip_to_surface',\n",
    "    'Q{num}',\n",
    "    'nQ{num}p',\n",
    "    'nQ{num}d',\n",
    "    'w500',\n",
    "    'w500_fine_res'\n",
    "]\n",
    "TIME_MEAN_SLICE = slice('20160805.023000', None)\n",
    "DROP_VARS = [\n",
    "    'column_heating_nudge',\n",
    "    'column_moistening_nudge',\n",
    "    'column_mass_tendency_nudge',\n",
    "    'column_integrated_dQu',\n",
    "    'column_integrated_dQv',\n",
    "    'net_heating',\n",
    "    'net_moistening',\n",
    "]\n",
    "STATE_VARS = [\n",
    "    'pressure_thickness_of_atmospheric_layer',\n",
    "    'vertical_thickness_of_atmospheric_layer',\n",
    "    'surface_geopotential',\n",
    "    'specific_humidity',\n",
    "    'air_temperature',\n",
    "    'eastward_wind',\n",
    "    'northward_wind'\n",
    "]\n",
    "Q1_SCALE = dict(vmin=-5, vmax=5)\n",
    "TIMESTEP_SECONDS = 10800\n",
    "SECONDS_PER_DAY = 86400\n",
    "G_PER_KG = 1000\n",
    "INSTANTANEOUS_TIMESTAMP = '20160805.143000'\n",
    "OUTDIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_variables(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Compute selected derived variables from a physics dataset\n",
    "    and merge them back in.\n",
    "    \n",
    "    Args:\n",
    "        ds: Dataset to calculated derived values from and merge to\n",
    "    \"\"\"\n",
    "    arrays = []\n",
    "    for func in [\n",
    "        _total_precip_to_surface,\n",
    "        _column_nq1,\n",
    "        _column_nq2\n",
    "    ]:\n",
    "        try:\n",
    "            arrays.append(func(ds))\n",
    "        except (KeyError, AttributeError):  # account for ds[var] and ds.var notations\n",
    "            logger.warning(f\"Missing variable for calculation in {func.__name__}\")\n",
    "    return ds.merge(xr.merge(arrays))\n",
    "\n",
    "\n",
    "def _column_nq1(ds: xr.Dataset) -> xr.DataArray:\n",
    "    column_nq1 = ds.net_heating_due_to_nudging\n",
    "    column_nq1.attrs = {\n",
    "        \"long_name\": \"<nQ1> column integrated heating from nudging\",\n",
    "        \"units\": \"W/m^2\",\n",
    "    }\n",
    "    return column_nq1.rename(\"column_integrated_nQ1\")\n",
    "\n",
    "\n",
    "def _column_nq2(ds: xr.Dataset) -> xr.DataArray:\n",
    "    column_nq2 = SECONDS_PER_DAY * ds.net_moistening_due_to_nudging\n",
    "    column_nq2.attrs = {\n",
    "        \"long_name\": \"<nQ2> column integrated moistening from nudging\",\n",
    "        \"units\": \"mm/day\",\n",
    "    }\n",
    "    return column_nq2.rename(\"column_integrated_nQ2\")\n",
    "\n",
    "\n",
    "def _total_precip_to_surface(ds: xr.Dataset) -> xr.DataArray:\n",
    "    total_precip_to_surface = ds.total_precipitation_rate * SECONDS_PER_DAY\n",
    "    total_precip_to_surface.attrs = {\n",
    "        \"long_name\": \"total precip to surface (max(PRATE-<dQ2>-<nQ2>, 0))\",\n",
    "        \"units\": \"mm/day\",\n",
    "    }\n",
    "    return total_precip_to_surface.rename(\"total_precip_to_surface\")\n",
    "\n",
    "def tendency_units(ds):\n",
    "    for var in ds.data_vars:\n",
    "        ds[var] = ds[var] * TIMESTEP_SECONDS\n",
    "        if \"specific_humidity\" in var:\n",
    "            ds[var] = ds[var] * G_PER_KG\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_average(ds, freq='3H'):\n",
    "    ds = ds.resample({'time': freq}, base=1, loffset=timedelta(minutes=90)).mean()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nudge-to-fine run dataset\n",
    "nudging_tendencies = tendency_units(standardize_fv3_diagnostics(\n",
    "    intake.open_zarr(os.path.join(N2F_URL, 'nudging_tendencies.zarr'), consolidated=True).to_dask()\n",
    "))\n",
    "physics_tendencies = tendency_units(standardize_fv3_diagnostics(\n",
    "    intake.open_zarr(os.path.join(N2F_URL, 'physics_tendencies.zarr'), consolidated=True).to_dask()\n",
    "))\n",
    "states = time_average(standardize_fv3_diagnostics(\n",
    "    get_variables(\n",
    "        intake.open_zarr(os.path.join(N2F_URL, 'state_after_timestep.zarr'), consolidated=True).to_dask(),\n",
    "        STATE_VARS\n",
    "    )\n",
    "))   \n",
    "physics_diags_nudging = time_average(standardize_fv3_diagnostics(\n",
    "    intake.open_zarr(os.path.join(N2F_URL, \"diags.zarr\"), consolidated=True).to_dask()\n",
    "))\n",
    "physics_diags_sfc = time_average(standardize_fv3_diagnostics(\n",
    "    intake.open_zarr(os.path.join(N2F_URL, \"sfc_dt_atmos.zarr\"), consolidated=True).to_dask()\n",
    "))\n",
    "physics_diags = physics_variables(\n",
    "    xr.merge([physics_diags_nudging, physics_diags_sfc])\n",
    ").drop_vars(names=DROP_VARS, errors='ignore')\n",
    "dycore = time_average(standardize_fv3_diagnostics(\n",
    "    intake.open_zarr(os.path.join(N2F_URL, 'atmos_dt_atmos.zarr'), consolidated=True).to_dask()\n",
    "))['w500']\n",
    "run_dataset = xr.merge([nudging_tendencies, physics_tendencies, states, physics_diags, dycore], join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif = time_average(standardize_fv3_diagnostics(CATALOG[VERIFICATION_ENTRY].to_dask()))['w500'].rename('w500_fine_res')\n",
    "run_dataset = xr.merge([run_dataset, verif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heights_and_pressures(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \n",
    "    ds = ds.assign({\n",
    "        'pressure': 0.01*thermo.pressure_at_midpoint_log(\n",
    "            ds['pressure_thickness_of_atmospheric_layer'],\n",
    "            dim='z'\n",
    "        ).assign_attrs({\n",
    "            'long_name': \"pressure at layer center\",\n",
    "            'units': 'hPa'\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    ds = ds.assign({\n",
    "        'pressure_interface': 0.01*thermo.pressure_at_interface(\n",
    "            ds['pressure_thickness_of_atmospheric_layer'],\n",
    "            dim_center='z',\n",
    "            dim_outer='zb'\n",
    "        ).assign_attrs({\n",
    "            'long_name': \"pressure at layer interface\",\n",
    "            'units': 'hPa'\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    ds = ds.assign({\n",
    "        'height': thermo.height_at_midpoint(\n",
    "            ds['vertical_thickness_of_atmospheric_layer'],\n",
    "            ds['surface_geopotential'],\n",
    "            dim='z'\n",
    "        ).assign_attrs({\n",
    "            'long_name': \"height at layer center\",\n",
    "            'units': 'm'\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    ds = ds.assign({\n",
    "        'height_interface': thermo.height_at_interface(\n",
    "            ds['vertical_thickness_of_atmospheric_layer'],\n",
    "            ds['surface_geopotential'],\n",
    "            dim_center='z',\n",
    "            dim_outer='zb'\n",
    "        ).assign_attrs({\n",
    "            'long_name': \"height at layer interface\",\n",
    "            'units': 'm'\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dataset = add_heights_and_pressures(run_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open grid and merge, overriding grid vars in fortran diagnostics because repeated values in time mess with the kdtree\n",
    "grid_c48 = standardize_fv3_diagnostics(CATALOG[\"grid/c48\"].to_dask())\n",
    "run_dataset = xr.merge([grid_c48, run_dataset], compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine-res apparent sources dataset\n",
    "ds = intake.open_zarr(FINE_RES_ZARR).to_dask()\n",
    "common_time = ds.time.loc[ds.time > (run_dataset.time[0] - timedelta(minutes=90))]\n",
    "ds = ds.sel(time=common_time)\n",
    "ds = ds.resample(time='3H', base=1, loffset=timedelta(minutes=90)).mean()\n",
    "fine_res_mapper = XarrayMapper(ds)\n",
    "RENAME = {\n",
    "    'pfull': 'z',\n",
    "    'dQ1': 'Q1',\n",
    "    'dQ2': 'Q2',\n",
    "    'omega': 'omega_fine_rs'\n",
    "}\n",
    "DIM_ORDER = (\"tile\", \"z\", \"grid_yt\", \"grid_xt\")\n",
    "fine_res_sources_mapper = FineResolutionSources(fine_res_mapper, rename_vars=RENAME, dim_order=DIM_ORDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TendencyCrossSectionMapper(GeoMapper):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: xr.Dataset,\n",
    "        fine_res_mapping: Mapping[str, xr.Dataset],\n",
    "        transect: Mapping[str, xr.Dataset],\n",
    "        primary_var: str,\n",
    "        other_vars: Sequence[str],\n",
    "        title: str,\n",
    "        units: str='kg/kg/s',\n",
    "        scale: float=25\n",
    "    ):\n",
    "        self._dataset = dataset\n",
    "        self._fine_res = fine_res_mapping\n",
    "        self.primary_var = primary_var\n",
    "        self._other_vars = other_vars\n",
    "        self._transect = transect\n",
    "        self.title = title\n",
    "        self.units = units\n",
    "        self.scale = scale\n",
    "        \n",
    "        times = self._dataset.time.values.tolist()\n",
    "        time_strings = [encode_time(time) for time in times]\n",
    "        self._time_lookup = dict(zip(time_strings, times))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, key: Union[str, slice]) -> xr.Dataset:\n",
    "        \n",
    "        if isinstance(key, str):\n",
    "            ds = self._get_timestep(key)\n",
    "        elif isinstance(key, slice):\n",
    "            ds = self._get_timeslice(key)\n",
    "        ds = self._derive_components(ds)\n",
    "        ds = get_variables(ds, [self.primary_var] + self._other_vars)\n",
    "        with ProgressBar():\n",
    "            print(f'Loading data for {key}')\n",
    "            return ds.load()\n",
    "        \n",
    "    def _get_timestep(self, key: str) -> Tuple[xr.Dataset, xr.Dataset]:\n",
    "        fine_res = standardize_fv3_diagnostics(self._fine_res[key])\n",
    "        nudged = (\n",
    "            self._dataset\n",
    "            .sel(time=self._time_lookup[key])\n",
    "            .drop_vars('time').expand_dims({'time': [key]})\n",
    "        )\n",
    "        ds = xr.merge([nudged, fine_res], compat='override')\n",
    "        return interpolate_unstructured(ds, self._transect).expand_dims({'time': ds.time})\n",
    "    \n",
    "    def _get_timeslice(self, key_slice: slice) -> Tuple[xr.Dataset, xr.Dataset]:\n",
    "        timesteps = sorted(self._time_lookup.keys())\n",
    "        start = timesteps.index(key_slice.start) if key_slice.start is not None else None\n",
    "        end = timesteps.index(key_slice.stop) if key_slice.stop is not None else None\n",
    "        step = key_slice.step if key_slice.step is not None else None\n",
    "        timestep_subset = timesteps[start:end:step]\n",
    "        fine_res = standardize_fv3_diagnostics(\n",
    "            xr.concat(\n",
    "                [self._fine_res[timestep] for timestep in timestep_subset],\n",
    "                dim='time'\n",
    "            )\n",
    "        )\n",
    "        nudged = (\n",
    "            self._dataset\n",
    "            .isel(time=slice(start, end, step))\n",
    "            .assign_coords({'time': timestep_subset})\n",
    "        )\n",
    "        ds = xr.merge([nudged, fine_res], compat='override')\n",
    "        return interpolate_unstructured(ds, self._transect)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _derive_components(ds: xr.Dataset) -> xr.Dataset:\n",
    "        ds['nQ1p'] = TIMESTEP_SECONDS*ds['Q1'] - ds['tendency_of_air_temperature_due_to_fv3_physics']\n",
    "        ds['nQ1d'] = ds['air_temperature_tendency_due_to_nudging'] - ds['nQ1p']\n",
    "        ds['nQ2p'] = G_PER_KG*TIMESTEP_SECONDS*ds['Q2'] - ds['tendency_of_specific_humidity_due_to_fv3_physics']\n",
    "        ds['nQ2d'] = ds['specific_humidity_tendency_due_to_nudging'] - ds['nQ2p']\n",
    "        return ds\n",
    "        \n",
    "    def keys(self):\n",
    "        return self._time_lookup.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transect_frame(time, ds, axes, var, pcolor_kwargs, title, yscale):\n",
    "\n",
    "    LEVELS, UNITS_CONV, NUM, LETTER = (\n",
    "        (range(0, 50, 5), G_PER_KG, '2', 'q')\n",
    "        if var == 'specific_humidity' else (range(200, 300, 20), 1, '1', 'T')\n",
    "    )\n",
    "    ds = ds.sel(time=time)\n",
    "    \n",
    "    ax0 = axes[0]\n",
    "    ax0.clear()\n",
    "    ax0.pcolormesh(\n",
    "        ds['transect'],\n",
    "        ds['pressure'],\n",
    "        ds[f'{var}_tendency_due_to_nudging'],\n",
    "        shading='nearest',\n",
    "        **pcolor_kwargs\n",
    "    )\n",
    "    hsphum = ax0.contour(\n",
    "        ds['transect'].broadcast_like(ds['pressure']),\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*ds[var],\n",
    "        colors='k',\n",
    "        levels=LEVELS,\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    ax0.clabel(hsphum, fontsize='x-small', fmt='%u', inline_spacing=1)\n",
    "    ax0.set_ylim([1e3, 2e2])\n",
    "    ax0.set_ylabel('pressure [hPa]')\n",
    "    ax0.set_facecolor('olive')\n",
    "    ax0.set_title(f'a) nudging tendency (nQ{LETTER})')\n",
    "    ax1 = axes[1]\n",
    "    ax1.clear()\n",
    "    ax1.pcolormesh(\n",
    "        ds['transect'],\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*TIMESTEP_SECONDS*ds[f'Q{NUM}'],\n",
    "        shading='nearest',\n",
    "        **pcolor_kwargs\n",
    "    )\n",
    "    hsphum = ax1.contour(\n",
    "        ds['transect'].broadcast_like(ds['pressure']),\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*ds[var],\n",
    "        colors='k',\n",
    "        levels=LEVELS,\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.clabel(hsphum, fontsize='x-small', fmt='%u', inline_spacing=1)\n",
    "    ax1.set_ylim([1e3, 2e2])\n",
    "    ax1.set_facecolor('olive')\n",
    "    ax1.set_title(f'b) fine-res apparent source (Q{LETTER})')\n",
    "    ax2 = axes[2]\n",
    "    ax2.clear()\n",
    "    ax2.pcolormesh(\n",
    "        ds['transect'],\n",
    "        ds['pressure'],\n",
    "        ds[f'nQ{NUM}p'],\n",
    "        shading='nearest',\n",
    "        **pcolor_kwargs\n",
    "    )\n",
    "    hsphum = ax2.contour(\n",
    "        ds['transect'].broadcast_like(ds['pressure']),\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*ds[var],\n",
    "        colors='k',\n",
    "        levels=LEVELS,\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.clabel(hsphum, fontsize='x-small', fmt='%u', inline_spacing=1)\n",
    "    ax2.set_ylabel('pressure [hPa]')\n",
    "    ax2.set_ylim([1e3, 2e2])\n",
    "    ax2.set_facecolor('olive')\n",
    "    ax2.set_title(f'c) nudging tendency due to physics (nQ{LETTER}p)')\n",
    "    ax3 = axes[3]\n",
    "    ax3.clear()\n",
    "    ax3.pcolormesh(\n",
    "        ds['transect'],\n",
    "        ds['pressure'],\n",
    "        ds[f'tendency_of_{var}_due_to_fv3_physics'],\n",
    "        shading='nearest',\n",
    "        **pcolor_kwargs\n",
    "    )\n",
    "    hsphum = ax3.contour(\n",
    "        ds['transect'].broadcast_like(ds['pressure']),\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*ds[var],\n",
    "        colors='k',\n",
    "        levels=LEVELS,\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    ax3.invert_yaxis()\n",
    "    ax3.clabel(hsphum, fontsize='x-small', fmt='%u', inline_spacing=1)\n",
    "    ax3.set_ylim([1e3, 2e2])\n",
    "    ax3.set_facecolor('olive')\n",
    "    ax3.set_title(f'd) physics tendency (pQ{LETTER})')\n",
    "    ax4 = axes[4]\n",
    "    ax4.clear()\n",
    "    ax4.pcolormesh(\n",
    "        ds['transect'],\n",
    "        ds['pressure'],\n",
    "        ds[f'nQ{NUM}d'],\n",
    "        shading='nearest',\n",
    "        **pcolor_kwargs\n",
    "    )\n",
    "    hsphum = ax4.contour(\n",
    "        ds['transect'].broadcast_like(ds['pressure']),\n",
    "        ds['pressure'],\n",
    "        UNITS_CONV*ds[var],\n",
    "        colors='k',\n",
    "        levels=LEVELS,\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.clabel(hsphum, fontsize='x-small', fmt='%u', inline_spacing=1)\n",
    "    ax4.set_xlabel('deg along transect')\n",
    "    ax4.set_ylim([1e3, 2e2])\n",
    "    ax4.set_ylabel('pressure [hPa]')\n",
    "    ax4.set_facecolor('olive')\n",
    "    ax4.set_title(f'e) nudging tendency due to dynamics (nQ{LETTER}d)')\n",
    "    ax5 = axes[5]\n",
    "    ax5.clear()\n",
    "    if var == 'specific_humidity':\n",
    "        h1 = ax5.plot(\n",
    "            ds['transect'],\n",
    "            SECONDS_PER_DAY*ds['PRATEsfc'],\n",
    "            color='b',\n",
    "            label='coarse model physics precipitation'\n",
    "        )\n",
    "        h2 = ax5.plot(\n",
    "            ds['transect'],\n",
    "            ds['total_precip_to_surface'],\n",
    "            color='orange',\n",
    "            label='fine-res model precipitation'\n",
    "        )\n",
    "        h3 = ax5.plot(\n",
    "            ds['transect'],\n",
    "            -ds['column_integrated_nQ2'],\n",
    "            color='gray',\n",
    "            label='column integrated drying from nudging'\n",
    "        )\n",
    "        ax5.set_ylabel('mm/day')\n",
    "        ax5.set_title('f) winds and integrated moisture tendencies')\n",
    "        handles = h1 + h2 + h3\n",
    "    elif var == 'air_temperature':\n",
    "        handles = ax5.plot(\n",
    "            ds['transect'],\n",
    "            ds['column_integrated_nQ1'],\n",
    "            color='b',\n",
    "            label='column integrated warming from nudging'\n",
    "        )\n",
    "        ax5.set_ylabel('W/m^2')\n",
    "        ax5.set_title('f) winds and integrated temperature tendencies')\n",
    "    ax5.set_xlabel('deg along transect')\n",
    "    ax5.set_ylim([-yscale, yscale])\n",
    "    ax5.grid(axis='y')\n",
    "    ax5.legend(handles, [h.get_label() for h in handles], loc='lower left', bbox_to_anchor=(0, 0), fontsize='x-small')\n",
    "    ax5b = axes[6]\n",
    "    ax5b.clear()\n",
    "    hw = ax5b.plot(ds['transect'], 100*(ds['w500'] - ds['w500_fine_res']), label='w500 bias, coarse - fine', color='g', ls='-')\n",
    "    ax5b.set_ylim([-10, 10])\n",
    "    ax5b.set_yticks(np.linspace(-10, 10, 5))\n",
    "    ax5b.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%2.0f'))\n",
    "    ax5b.set_ylabel('cm/s')\n",
    "    ax5b.legend(hw, [h.get_label() for h in hw], loc='upper right', fontsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_axes(pcolor_kwargs, units):\n",
    "    fig = plt.figure()\n",
    "    axes = list(fig.subplots(3, 2, sharex=True).flatten())\n",
    "    norm = matplotlib.colors.Normalize(vmin=pcolor_kwargs['vmin'], vmax=pcolor_kwargs['vmax'])\n",
    "    sm = plt.cm.ScalarMappable(cmap=pcolor_kwargs['cmap'], norm=norm)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, ax=axes, label=units)\n",
    "    wind_ax = axes[-1].twinx()\n",
    "    wind_ax.set_position(axes[-1].get_position())\n",
    "    axes.append(wind_ax)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantaneous_transect(transect_mapper, time, fig_size=[12, 10], dpi=150, pcolor_kwargs=None):\n",
    "\n",
    "    pcolor_kwargs = pcolor_kwargs or {}\n",
    "    if 'vmin' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmin'] = -2.5\n",
    "    if 'vmax' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmax'] = 2.5\n",
    "    if 'cmap' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['cmap'] = 'seismic'\n",
    "\n",
    "    fig, axes = get_frame_axes(pcolor_kwargs, transect_mapper.units)\n",
    "\n",
    "    ds = transect_mapper[time]\n",
    "    _transect_frame(time, ds, axes, transect_mapper.primary_var, pcolor_kwargs, transect_mapper.title, transect_mapper.scale)\n",
    "\n",
    "    fig.set_size_inches(fig_size)\n",
    "    fig.set_dpi(dpi)\n",
    "    plt.savefig(f\"{OUTDIR}/{transect_mapper.title.replace(' ', '_')}_{time}.png\", bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mean_transect(transect_mapper, time_slice, fig_size=[12, 10], dpi=150, pcolor_kwargs=None):\n",
    "    \n",
    "    pcolor_kwargs = pcolor_kwargs or {}\n",
    "    if 'vmin' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmin'] = -1.0\n",
    "    if 'vmax' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmax'] = 1.0\n",
    "    if 'cmap' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['cmap'] = 'seismic'\n",
    "\n",
    "    fig, axes = get_frame_axes(pcolor_kwargs, transect_mapper.units)\n",
    "    \n",
    "    ds_mean = transect_mapper[time_slice].mean(dim='time').expand_dims({'time': ['time-mean']})\n",
    "    _transect_frame('time-mean', ds_mean, axes, transect_mapper.primary_var, pcolor_kwargs, transect_mapper.title, transect_mapper.scale)\n",
    "\n",
    "    fig.set_size_inches(fig_size)\n",
    "    fig.set_dpi(dpi)\n",
    "    plt.savefig(f\"{OUTDIR}/{transect_mapper.title.replace(' ', '_')}_time_mean.png\", bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_transect(transect_mapper, time_slice, fig_size=[12, 10], dpi=150, pcolor_kwargs=None, func_animation_kwargs=None):\n",
    "    \n",
    "    pcolor_kwargs = pcolor_kwargs or {}\n",
    "    func_animation_kwargs = func_animation_kwargs or {}\n",
    "    \n",
    "    if 'vmin' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmin'] = -2.5\n",
    "    if 'vmax' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['vmax'] = 2.5\n",
    "    if 'cmap' not in pcolor_kwargs:\n",
    "        pcolor_kwargs['cmap'] = 'seismic'\n",
    "\n",
    "    fig, axes = get_frame_axes(pcolor_kwargs, transect_mapper.units)\n",
    "    \n",
    "    ds = transect_mapper[time_slice]\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig,\n",
    "        _transect_frame,\n",
    "        frames=ds.time.values,\n",
    "        fargs=(ds, axes, transect_mapper.primary_var, pcolor_kwargs, transect_mapper.title, transect_mapper.scale),\n",
    "        **func_animation_kwargs\n",
    "    )\n",
    "\n",
    "    fig.set_size_inches(fig_size)\n",
    "    fig.set_dpi(dpi)\n",
    "    anim_html = HTML(anim.to_html5_video())\n",
    "    plt.close(fig)\n",
    "    anim.save(f\"{OUTDIR}/{transect_mapper.title.replace(' ', '_')}.mp4\", savefig_kwargs={'bbox_inches': 'tight'})\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meridional_transect(lon, lat_start, lat_stop, lat_res):\n",
    "    lat = np.arange(lat_start, lat_stop, lat_res)\n",
    "    lon = np.ones_like(lat) * lon\n",
    "    return {\n",
    "        'lat': xr.DataArray(lat, dims=['transect'], coords={'transect': lat}),\n",
    "        'lon': xr.DataArray(lon, dims=['transect'], coords={'transect': lat})\n",
    "    }\n",
    "\n",
    "def zonal_transect(lat, lon_start, lon_stop, lon_res):\n",
    "    lon = np.arange(lon_start, lon_stop, lon_res)\n",
    "    lat = np.ones_like(lon) * lat\n",
    "    return {\n",
    "        'lat': xr.DataArray(lat, dims=['transect'], coords={'transect': lon}),\n",
    "        'lon': xr.DataArray(lon, dims=['transect'], coords={'transect': lon})\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahara_transect = meridional_transect(0, 0, 42, 1)\n",
    "var = 'specific_humidity'\n",
    "sahara_moisture_tendency_xs_mapper = TendencyCrossSectionMapper(\n",
    "    run_dataset,\n",
    "    fine_res_sources_mapper,\n",
    "    sahara_transect,\n",
    "    var,\n",
    "    [var_template.format(var=var, num=VAR_MAPPING[var]) for var_template in PLOT_VARS],\n",
    "    'Sahara (lon=0, lat=[0, 42N]) moisture',\n",
    "    units='g/kg/3-hr'\n",
    ")\n",
    "var = 'air_temperature'\n",
    "sahara_temperature_tendency_xs_mapper = TendencyCrossSectionMapper(\n",
    "    run_dataset,\n",
    "    fine_res_sources_mapper,\n",
    "    sahara_transect,\n",
    "    var,\n",
    "    [var_template.format(var=var, num=VAR_MAPPING[var]) for var_template in PLOT_VARS],\n",
    "    'Sahara (lon=0, lat=[0, 42N]) temperature',\n",
    "    scale=200,\n",
    "    units='K/3-hr'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_transect(sahara_moisture_tendency_xs_mapper, INSTANTANEOUS_TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mean_transect(sahara_moisture_tendency_xs_mapper, TIME_MEAN_SLICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_transect(\n",
    "    sahara_moisture_tendency_xs_mapper,\n",
    "    TIME_MEAN_SLICE,\n",
    "    func_animation_kwargs=dict(interval=250),\n",
    "    dpi=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_transect(sahara_temperature_tendency_xs_mapper, INSTANTANEOUS_TIMESTAMP, pcolor_kwargs=Q1_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mean_transect(sahara_temperature_tendency_xs_mapper, TIME_MEAN_SLICE, pcolor_kwargs=Q1_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_transect(\n",
    "    sahara_temperature_tendency_xs_mapper,\n",
    "    TIME_MEAN_SLICE,\n",
    "    func_animation_kwargs=dict(interval=250),\n",
    "    dpi=100,\n",
    "    pcolor_kwargs=Q1_SCALE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv3net kernel",
   "language": "python",
   "name": "fv3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
