{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b529f9c-74c6-465e-b624-6c549c3c9a5a",
   "metadata": {},
   "source": [
    "### prognostic drifts\n",
    "\n",
    "Figures showing drifts in variables over 40-day prognostic runs with various configurations (RF, NN, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c39327-f81e-4d58-85e6-660ad01498eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr\n",
    "import intake\n",
    "from matplotlib import pyplot as plt, ticker, dates as mdates\n",
    "import matplotlib as mpl\n",
    "from dask.diagnostics import ProgressBar\n",
    "import os\n",
    "from vcm.catalog import catalog as CATALOG\n",
    "from vcm.fv3.metadata import standardize_fv3_diagnostics\n",
    "from vcm.convenience import cast_to_datetime, convert_timestamps\n",
    "from vcm import interpolate_to_pressure_levels\n",
    "from vcm.select import zonal_average_approximate\n",
    "from typing import Mapping, Sequence\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7bc2f9-d80f-405d-9f29-02d1524879d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 8})\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "colors = [colors[ind] for ind in [0, 5, 8, 3]]\n",
    "colors.append('black')\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd593f52-6476-4540-8495-331252af5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = ['-', '-', '-', '-', '--']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors, linestyle=linestyles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d1e2b-280f-49a3-a11a-b63f9cb1e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = CATALOG['grid/c48'].to_dask()\n",
    "AREA = grid['area'].load()\n",
    "LAT = grid['lat'].load()\n",
    "\n",
    "DRIFT_TS_VARS = {\n",
    "    '200hPa temperature': {'tmp200_spatial_mean_dycore_global': 'TMP200'},\n",
    "    '850hPa temperature': {'tmp850_spatial_mean_dycore_global': 'TMP850'},\n",
    "    'precipitable water': {'pwat_spatial_mean_dycore_global': 'PWAT'},\n",
    "}\n",
    "\n",
    "RUN_KWARGS = [\n",
    "    {\n",
    "        'name': '$TqR$-RF',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/rf/initial_conditions_runs/20160805.000000']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TqR$-NN',\n",
    "        'url': {'state': [\"gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/nn-ensemble-model/initial_conditions_runs/20160805.000000\"]},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TquvR$-NN',\n",
    "        'url': {'state': [\"gs://vcm-ml-experiments/2021-05-11-nudge-to-c3072-corrected-winds/nn-ensemble-model/initial_conditions_runs_rectified_nn_rad/20160805.000000\"]},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': 'base no-ML',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-04-13/baseline-physics-run-20160805-start-rad-step-1800s']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': 'fine-grid',\n",
    "        'url': {\n",
    "            'state': ['40day_c48_restarts_as_zarr_may2020'],\n",
    "            'diags': ['40day_c48_atmos_8xdaily_additional_vars_may2020', '40day_c48_atmos_8xdaily_may2020']\n",
    "        },\n",
    "        'drift_vars': DRIFT_TS_VARS,\n",
    "        'verif': True\n",
    "    },\n",
    "    {\n",
    "        'name': '$TqR$-NN-seed-0',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/nn/seed-0/prognostic_run_sfc_rad']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TqR$-NN-seed-1',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/nn/seed-1/prognostic_run_sfc_rad']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TqR$-NN-seed-2',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/nn/seed-2/prognostic_run_sfc_rad']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TqR$-NN-seed-3',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-06-21-nudge-to-c3072-dq1-dq2-only/nn/seed-3/prognostic_run_sfc_rad']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TquvR$-NN-seed-0',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-05-11-nudge-to-c3072-corrected-winds/nn/seed-0/prognostic_run_sfc_rad_rectified']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TquvR$-NN-seed-1',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-05-11-nudge-to-c3072-corrected-winds/nn/seed-1/prognostic_run_sfc_rad_rectified']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TquvR$-NN-seed-2',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-05-11-nudge-to-c3072-corrected-winds/nn/seed-2/prognostic_run_sfc_rad_rectified']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    },\n",
    "    {\n",
    "        'name': '$TquvR$-NN-seed-3',\n",
    "        'url': {'state': ['gs://vcm-ml-experiments/2021-05-11-nudge-to-c3072-corrected-winds/nn/seed-3/prognostic_run_sfc_rad_rectified']},\n",
    "        'drift_vars': DRIFT_TS_VARS\n",
    "    }\n",
    "]\n",
    "\n",
    "DELP = 'pressure_thickness_of_atmospheric_layer'\n",
    "DELZ = 'vertical_thickness_of_atmospheric_layer'\n",
    "PHIS = 'surface_geopotential'\n",
    "T = 'air_temperature'\n",
    "q = 'specific_humidity'\n",
    "GRAVITY = 9.81\n",
    "LV = 2.5e6  # J/kg\n",
    "CP =  1004.  # J/kg/K\n",
    "\n",
    "VERIF_STATE_RENAME = {\n",
    "    'pfull': 'z',\n",
    "    'DZ': DELZ,\n",
    "    'delp': DELP,\n",
    "    'T': T,\n",
    "    'sphum': q,\n",
    "    'phis': PHIS\n",
    "}\n",
    "\n",
    "OUTDIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cd51e-3b1c-44cb-ab1a-c6b3b8d74305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(da, area, dims = ['x', 'y', 'tile']):\n",
    "    area = area.where(~np.isnan(da))\n",
    "    return ((da*area).sum(dim=dims))/(area.sum(dim=dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57c64a-8a7a-486d-9586-41ad8de5aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fv3gfsRun:\n",
    "    \n",
    "    def __init__(self, name, url, drift_vars, verif=False):\n",
    "        self.name: str = name\n",
    "        self.url: Mapping[str, Sequence[str]] = url\n",
    "        self.drift_vars: Mapping[str, Mapping[str, str]] = drift_vars\n",
    "        self.verif: bool = verif\n",
    "        self._diags: xr.Dataset = self._get_diags()\n",
    "        self._state: xr.Dataset = self._get_state()\n",
    "        with ProgressBar():\n",
    "            self.global_mean_ts: xr.Dataset = self._global_mean_ts().load()\n",
    "            mean_temp_lat_pressure, mean_temp_lat = self._mean_temp_lat_pressure()\n",
    "            self.mean_temp_lat_pressure: xr.DataArray = mean_temp_lat_pressure.load()\n",
    "            self.mean_temp_lat: xr.DataArray = mean_temp_lat.load()\n",
    "        \n",
    "    def _global_mean_ts(self):\n",
    "        global_mean_ts = {}\n",
    "        for plot_name, var_names in self.drift_vars.items():\n",
    "            diags_name = list(var_names.keys())[0]\n",
    "            verif_name = list(var_names.values())[0]\n",
    "            if diags_name in self._diags:\n",
    "                global_mean_ts[plot_name] = self._diags[diags_name]\n",
    "            else:\n",
    "                global_mean_ts[plot_name] = global_mean(self._diags[verif_name], AREA)\n",
    "        return xr.Dataset(global_mean_ts)\n",
    "    \n",
    "    def _mean_temp_lat(self):\n",
    "        T_pressure = interpolate_to_pressure_levels(self._state[T], self._state[DELP], dim='z')\n",
    "        T200_lat = zonal_average_approximate(LAT, T_pressure.sel({'pressure': 20000}))\n",
    "        T200_lat = T200_lat.sel({'time': T200_lat.time.loc[T200_lat.time >= np.datetime64('2016-08-21')]})\n",
    "        return T200_lat.mean('time').assign_attrs(self._state[T].attrs)\n",
    "    \n",
    "    def _mean_temp_lat_pressure(self):\n",
    "        T_pressure = interpolate_to_pressure_levels(self._state[T], self._state[DELP], dim='z')\n",
    "        T_pressure_lat = (\n",
    "            zonal_average_approximate(LAT, T_pressure)\n",
    "            .sel({'time': T_pressure.time.loc[T_pressure.time >= np.datetime64('2016-08-21')]})\n",
    "        )\n",
    "        T200_lat = T_pressure_lat.sel({'pressure': 20000})\n",
    "        T200_lat = T200_lat.mean('time').assign_attrs(self._state[T].attrs)\n",
    "        T_pressure_lat = T_pressure_lat.mean('time').assign_attrs(self._state[T].attrs)\n",
    "        return T_pressure_lat, T200_lat\n",
    "    \n",
    "    @staticmethod\n",
    "    def _subset_time(ds, hour, minute):\n",
    "        return ds.sel(time=ds.time.loc[\n",
    "            (ds.time.dt.hour == hour) & (ds.time.dt.minute == minute) \n",
    "            & (ds.time >= np.datetime64('2016-08-05')) \n",
    "            & (ds.time <= np.datetime64('2016-09-10')) \n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cast_to_datetime(ds):\n",
    "        cast = np.vectorize(cast_to_datetime)\n",
    "        return ds.assign_coords({'time': cast(ds.time)})\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convert_timestamps(ds):\n",
    "        return ds.assign_coords({'time': convert_timestamps(ds.time)})\n",
    "    \n",
    "    def _get_state(self):\n",
    "        if self.verif:\n",
    "            ds = self._get_verif_state()\n",
    "        else:\n",
    "            ds = self._get_prog_state()\n",
    "        return (\n",
    "            ds.pipe(self._cast_to_datetime)\n",
    "            .pipe(self._subset_time, hour=0, minute=0)\n",
    "        )      \n",
    "    \n",
    "    def _get_diags(self):\n",
    "        if self.verif:\n",
    "            ds = self._get_verif_diags()\n",
    "        else:\n",
    "            ds = self._get_prog_diags()\n",
    "        return (\n",
    "            ds.pipe(self._cast_to_datetime)\n",
    "            .pipe(self._subset_time, hour=0, minute=0)\n",
    "        ) \n",
    "    \n",
    "    def _get_verif_diags(self):\n",
    "        diags = []\n",
    "        for diags_path in self.url['diags']:\n",
    "            print(f\"Loading {self.name} diags at {diags_path}.\")\n",
    "            diags.append(standardize_fv3_diagnostics(CATALOG[diags_path].to_dask()))\n",
    "        return xr.merge(diags)\n",
    "    \n",
    "    def _get_verif_state(self):\n",
    "        assert len(self.url['state']) == 1\n",
    "        print(f\"Loading {self.name} state at {self.url['state'][0]}.\")\n",
    "        ds = CATALOG[self.url['state'][0]].to_dask()\n",
    "        return (\n",
    "            ds.pipe(self._convert_timestamps)\n",
    "            .pipe(standardize_fv3_diagnostics)\n",
    "            .rename(VERIF_STATE_RENAME)\n",
    "        )\n",
    "    \n",
    "    def _get_prog_diags(self):\n",
    "        assert len(self.url['state']) == 1\n",
    "        diags_path = self._get_diags_path(self.url['state'][0])\n",
    "        print(f\"Loading {self.name} diags at {diags_path}.\")\n",
    "        with fsspec.open(diags_path, 'rb') as f:\n",
    "            ds = xr.open_dataset(f).load()\n",
    "        return standardize_fv3_diagnostics(ds)\n",
    "            \n",
    "    def _get_prog_state(self):\n",
    "        state_path = os.path.join(self.url['state'][0], 'state_after_timestep.zarr')\n",
    "        print(f\"Loading {self.name} state at {state_path}.\")\n",
    "        return standardize_fv3_diagnostics(intake.open_zarr(state_path, consolidated=True).to_dask())\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_diags_path(run_url):\n",
    "        prefix = 'gs://vcm-ml-archive/prognostic_run_diags'\n",
    "        path_suffix = run_url.split('gs://')[1].replace(\"/\", \"-\")\n",
    "        return os.path.join(prefix, path_suffix, 'diags.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf0da4-e675-47fa-8fa5-805a7818bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = [Fv3gfsRun(**kwargs) for kwargs in RUN_KWARGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93954ab7-fb99-43a1-939d-01f397ddbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_global_ts(ax, runlist, var):\n",
    "    for run in [run for run in runlist if \"NN-seed\" not in run.name]:\n",
    "        ax.plot(run.global_mean_ts.time, run.global_mean_ts[var], label=run.name)\n",
    "    tqr_nn_seed_ds = xr.concat([run.global_mean_ts for run in runlist if \"$TqR$-NN-seed\" in run.name], dim='seed', join='inner')\n",
    "    ax.fill_between(\n",
    "        tqr_nn_seed_ds.time.values,\n",
    "        tqr_nn_seed_ds[var].min(dim='seed'),\n",
    "        tqr_nn_seed_ds[var].max(dim='seed'),\n",
    "        color=[h.get_color() for h in ax.get_lines() if h.get_label() == '$TqR$-NN'][0],\n",
    "        alpha=0.2\n",
    "    )\n",
    "    tquvr_nn_seed_ds = xr.concat([run.global_mean_ts for run in runlist if \"$TquvR$-NN-seed\" in run.name], dim='seed', join='inner')\n",
    "    ax.fill_between(\n",
    "        tquvr_nn_seed_ds.time.values,\n",
    "        tquvr_nn_seed_ds[var].min(dim='seed'),\n",
    "        tquvr_nn_seed_ds[var].max(dim='seed'),\n",
    "        color=[h.get_color() for h in ax.get_lines() if h.get_label() == '$TquvR$-NN'][0],\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax.set_xlim([np.datetime64('2016-08-06'), np.datetime64('2016-09-10')])\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation = 30)\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.SA))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.set_ylabel(runlist[0].global_mean_ts[var].attrs.get('units'))\n",
    "        \n",
    "def _plot_temp200_bias_lat(ax, runlist):\n",
    "    run_names = [run.name for run in runlist if 'NN-seed' not in run.name]\n",
    "    t200 = (\n",
    "        xr.concat(\n",
    "            [run.mean_temp_lat for run in runlist if 'NN-seed' not in run.name],\n",
    "            dim=xr.DataArray(run_names, dims='runs', coords={'runs': run_names})\n",
    "        )\n",
    "    ).assign_attrs({'units': 'K'})\n",
    "    h = t200.plot(ax=ax, hue='runs', add_legend=False)\n",
    "    tqr_nn_seed_ds = xr.concat([run.mean_temp_lat for run in runlist if \"$TqR$-NN-seed\" in run.name], dim='seed', join='inner')\n",
    "    ax.fill_between(\n",
    "        tqr_nn_seed_ds.lat.values,\n",
    "        tqr_nn_seed_ds.min(dim='seed'),\n",
    "        tqr_nn_seed_ds.max(dim='seed'),\n",
    "        color=[ax.get_color() for ax in ax.get_lines()][run_names.index(\"$TqR$-NN\")],\n",
    "        alpha=0.2\n",
    "    )\n",
    "    tquvr_nn_seed_ds = xr.concat([run.mean_temp_lat for run in runlist if \"$TquvR$-NN-seed\" in run.name], dim='seed', join='inner')\n",
    "    ax.fill_between(\n",
    "        tquvr_nn_seed_ds.lat.values,\n",
    "        tquvr_nn_seed_ds.min(dim='seed'),\n",
    "        tquvr_nn_seed_ds.max(dim='seed'),\n",
    "        color=[ax.get_color() for ax in ax.get_lines()][run_names.index(\"$TquvR$-NN\")],\n",
    "        alpha=0.2\n",
    "    )\n",
    "    ax.set_xlabel('latitude [deg]')\n",
    "    ax.set_xlim([-90, 90])\n",
    "    ax.set_ylabel('K')\n",
    "\n",
    "def plot_global_drifts(runlist, varnames):\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    for i, (ax, var) in enumerate(zip(axes.flatten(), varnames)):\n",
    "        if var != '200hPa time- and zonal-mean temperature':\n",
    "            _plot_global_ts(ax, runlist, var)\n",
    "        else:\n",
    "            _plot_temp200_bias_lat(ax, runlist)\n",
    "        ax.grid(axis='y')\n",
    "        ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:.1f}\"))\n",
    "        if i == 0:\n",
    "            h, l = ax.get_legend_handles_labels()\n",
    "            inds = [3, 0, 1, 2, 4]\n",
    "            h, l = [h[ind] for ind in inds], [l[ind] for ind in inds]\n",
    "            ax.legend(h, l, fontsize='small')\n",
    "        ax.set_title(f\"{string.ascii_lowercase[i]}) {var}\")\n",
    "    fig.set_size_inches([7.6, 6])\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{OUTDIR}/Figure_A7_prognostic_drifts.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35f1b9-ad28-4160-aa8d-8666d5da877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_drifts(run_list, list(DRIFT_TS_VARS.keys()) + ['200hPa time- and zonal-mean temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee084f5-1ba9-48e0-9bd0-628ebbc423b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv3net kernel",
   "language": "python",
   "name": "fv3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
